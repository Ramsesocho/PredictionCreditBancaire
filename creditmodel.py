# -*- coding: utf-8 -*-
"""CreditModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XYx-3GaUmW0cptjxzdPZYkJl4pcvcUlK
"""

# import les packages

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

"""#1- Collecte,Nettoyage,Traitement Des Données


"""

#Lecture de la base de données
df=pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')
df

#examiner la base de données
pd.set_option('display.max_rows',df.shape[0]+1)

df

pd.set_option('display.max_rows',10)

df

# voir les valeurs manquantes
df.info()

df.isnull().sum().sort_values(ascending=False)

df.describe()

df.describe(include='O')

# Renseigner les valeurs manquantes
cat_data=[]
num_data=[]
for i,c in enumerate(df.dtypes):
  if c==object:
    cat_data.append(df.iloc[:,i])
  else:
    num_data.append(df.iloc[:,i])
cat_data=pd.DataFrame(cat_data).transpose()
num_data=pd.DataFrame(num_data).transpose()

cat_data

num_data

df.dtypes

#Traitement Pour les variables catégoriques
cat_data=cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))
cat_data.isnull().sum().any()

cat_data['Education'].value_counts()

#Traitement pour les variables numériques
num_data.fillna(method='bfill',inplace=True)
num_data.isnull().sum().any()

# Tranformer la colonne target
target_value={'Y':1,'N':0}
target=cat_data['Loan_Status']
cat_data.drop('Loan_Status', axis=1, inplace=True)
target=target.map(target_value)
target

from sklearn.preprocessing import LabelEncoder

#Remplacer les valeurs catégorique par des valeurs numérique 0,1,2 ....
le=LabelEncoder()
for i in cat_data:
  cat_data[i]=le.fit_transform(cat_data[i])
cat_data

#Supprimer loan_id
cat_data.drop('Loan_ID',axis=1,inplace=True)

#Concatener les variable categoriques  et les varibles numéroques
X=pd.concat([cat_data,num_data],axis=1)
y=target

X

"""#2- Analyse Exploratoire"""

# Analyse de la varible target
target.value_counts()

# la base de données utilisées pour l'analyse exploratoire

df=pd.concat([cat_data,num_data,target],axis=1)

df





counts = [target.value_counts()[0], target.value_counts()[1]]
yes = counts[0] / len(target)
no = counts[1] / len(target)

print(f'le pourcentage des credits accordés est : {yes:.2%}')
print(f'le pourcentage des credits non accordés est : {no:.2%}')

plt.figure(figsize=(8, 6))
plt.bar(['Crédits accordés', 'Crédits non accordés'], counts, color=['blue', 'orange'])
plt.xlabel('Catégorie')
plt.ylabel('Nombre')
plt.title('Répartition des crédits accordés et non accordés')
plt.show()

# Credit history

grid = sns.FacetGrid(df, col='Loan_Status', height=3.2, aspect=1.6)
grid.map(sns.countplot, 'Credit_History')

plt.show()

# Sexe

grid = sns.FacetGrid(df, col='Loan_Status', height=3.2, aspect=1.6)
grid.map(sns.countplot, 'Gender')

plt.show()

# Revenu du demandeur
plt.scatter(df['ApplicantIncome'],df['Loan_Status'])

# Division de la base de données en une base de données test et d'entrainement
from sklearn.model_selection import StratifiedShuffleSplit,train_test_split

sss=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)

for train,test in sss.split(X,y):
  X_train,X_test=X.iloc[train],X.iloc[test]
  y_train,y_test=y.iloc[train],y.iloc[test]

print('X_train taille :', X_train.shape)
print('X_test taille :', X_test.shape)
print('y_train taille :', y_train.shape)
print('y_test taille :', y_test.shape)

# Je souhaite appliquer 3 modeles , evaluer et choisir le meilleur Logistic Regression,KNN,DecisionTree
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

models={
    'LogisticRegression':LogisticRegression(random_state=42),
    'KNeighborsClassifier':KNeighborsClassifier(),
    'DecisionTreeClassifier':DecisionTreeClassifier(max_depth=1,random_state=42)
}

#La fonction de la precision

def accu(y_true,y_pred,retu=False):
  acc=accuracy_score(y_true,y_pred)
  if retu:
    return acc
  else:
    print(f'la precision du modele est  {acc}')


#la fonction d'application des modeles

def train_test_eval(models,X_train,y_train,X_test,y_test):
  for name,model in models.items():
    print(name,':')
    model.fit(X_train,y_train)
    accu(y_test,model.predict(X_test))
    print('-'*30)

train_test_eval(models,X_train,y_train,X_test,y_test)

X_2=X[['Credit_History','Married','CoapplicantIncome']]

sss=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)

for train,test in sss.split(X_2,y):
  X_train,X_test=X_2.iloc[train],X_2.iloc[test]
  y_train,y_test=y.iloc[train],y.iloc[test]

print('X_train taille :', X_train.shape)
print('X_test taille :', X_test.shape)
print('y_train taille :', y_train.shape)
print('y_test taille :', y_test.shape)

train_test_eval(models,X_train,y_train,X_test,y_test)

#Appliquer la regression logistique sur notre base de données
Classifier=LogisticRegression()
Classifier.fit(X_2,y)

#Enregistrer le modele
pickle.dump(Classifier,open('model.pkl','wb'))